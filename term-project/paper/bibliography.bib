@article{DeCock2011,
  author          = {{De Cock}, Dean},
  journal         = {Journal of Statistics Education},
  keywords        = {Assessed Value,Group Project,Linear Models,Multiple Regression},
  mendeley-groups = {DI501},
  number          = {3},
  title           = {{Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project}},
  url             = {www.amstat.org/publications/jse/v19n3/decock.pdf},
  volume          = {19},
  year            = {2011}
}

@article{Breiman2001,
  abstract        = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
  author          = {Breiman, Leo},
  doi             = {10.1023/A:1010933404324},
  issn            = {1573-0565},
  journal         = {Machine Learning 2001 45:1},
  keywords        = {Artificial Intelligence,Control,Mechatronics,Natural Language Processing (NLP),Robotics,Simulation and Modeling},
  mendeley-groups = {DI501},
  month           = {oct},
  number          = {1},
  pages           = {5--32},
  publisher       = {Springer},
  title           = {{Random Forests}},
  url             = {https://link.springer.com/article/10.1023/A:1010933404324},
  volume          = {45},
  year            = {2001}
}

@book{molnar2019,
  title     = {Interpretable Machine Learning},
  author    = {Christoph Molnar},
  year      = {2019},
  publisher = {Github},
  subtitle  = {A Guide for Making Black Box Models Explainable}
}

@article{Fisher2019,
  author          = {Fisher, Aaron J. and Rudin, C. and Dominici, F.},
  journal         = {undefined},
  mendeley-groups = {DI501},
  title           = {{All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously}},
  year            = {2019}
}

@article{shapley1953value,
  title   = {A value fo n-person Games},
  author  = {Shapley, Lloyd},
  journal = {Ann. Math. Study28, Contributions to the Theory of Games, ed. by HW Kuhn, and AW Tucker},
  pages   = {307--317},
  year    = {1953}
}

@article{Lundberg2017,
  abstract        = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
  author          = {Lundberg, Scott M and Allen, Paul G and Lee, Su-In},
  journal         = {Advances in Neural Information Processing Systems},
  mendeley-groups = {DI501},
  title           = {{A Unified Approach to Interpreting Model Predictions}},
  url             = {https://github.com/slundberg/shap},
  volume          = {30},
  year            = {2017}
}

@inproceedings{pandas,
  author    = { Wes McKinney },
  title     = { Data Structures for Statistical Computing in Python },
  booktitle = { Proceedings of the 9th Python in Science Conference },
  pages     = { 51--56 },
  year      = { 2010 },
  editor    = { Stefan van der Walt and Jarrod Millman }
}

@misc{scipy,
  author = {Eric Jones and Travis Oliphant and Pearu Peterson and others},
  title  = {{SciPy}: Open source scientific tools for {Python}},
  year   = {2001--},
  url    = {http://www.scipy.org/},
  note   = {[Online; accessed <today>]}
}

@article{numpy,
  author  = {Stéfan van der Walt, S. Chris Colbert and Gaël Varoquaux},
  title   = {The NumPy Array: A Structure for Efficient Numerical Computation},
  journal = {Computing in Science & Engineering},
  volume  = 13,
  pages   = {22--30},
  year    = 2011,
  doi     = {10.1109/MCSE.2011.37}
}

@article{matplotlib,
  author  = {John D. Hunter},
  title   = {Matplotlib: A 2D Graphics Environment},
  year    = 2007,
  volume  = 9,
  pages   = {90--95},
  journal = {Computing in Science & Engineering},
  doi     = {10.1109/MCSE.2007.55}
}

@article{Bilogur2018,
  abstract        = {Algorithmic models and outputs are only as good as the data they are computed on. As the popular saying goes: garbage in, garbage out. In tabular datasets, it is usually relatively easy to, at a glance, understand patterns of missing data (or nullity) of individual rows, columns, and entries. However, it is far harder to see patterns in the missingness of data that extend between them. Understanding such patterns in data is beneficial, if not outright critical, to most applications. missingno is a Python package for visualizing missing data. It works by converting tabular data matrices into boolean masks based on whether individual entries contain data (which evaluates to true) or left empty (which evaluates to false). This “nullity matrix” is then exposed to user assessment through a variety of special-purpose data visualizations.},
  author          = {Bilogur, Aleksey},
  doi             = {10.21105/JOSS.00547},
  issn            = {2475-9066},
  journal         = {Journal of Open Source Software},
  mendeley-groups = {DI501},
  month           = {feb},
  number          = {22},
  pages           = {547},
  publisher       = {The Open Journal},
  title           = {{Missingno: a missing data visualization suite}},
  url             = {https://joss.theoj.org/papers/10.21105/joss.00547},
  volume          = {3},
  year            = {2018}
}

@article{scikit-learn,
  title   = {Scikit-learn: Machine Learning in {P}ython},
  author  = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
             and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
             and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
             Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal = {Journal of Machine Learning Research},
  volume  = {12},
  pages   = {2825--2830},
  year    = {2011}
}

@article{tree-explainer,
  title     = {From local explanations to global understanding with explainable AI for trees},
  author    = {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In},
  journal   = {Nature Machine Intelligence},
  volume    = {2},
  number    = {1},
  pages     = {2522--5839},
  year      = {2020},
  publisher = {Nature Publishing Group}
}